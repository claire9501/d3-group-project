{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T02:42:52.297383Z",
     "start_time": "2020-08-19T02:42:51.813078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pompa\\Anaconda3\\envs\\usc_bootcamp\\lib\\site-packages\\setuptools\\distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : None\n",
      "python           : 3.7.1.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : None.None\n",
      "\n",
      "pandas           : 1.0.5\n",
      "numpy            : 1.18.5\n",
      "pytz             : 2020.1\n",
      "dateutil         : 2.8.1\n",
      "pip              : 20.1.1\n",
      "setuptools       : 49.2.0.post20200714\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : 4.5.1\n",
      "html5lib         : 1.0.1\n",
      "pymysql          : None\n",
      "psycopg2         : 2.8.5 (dt dec pq3 ext lo64)\n",
      "jinja2           : 2.11.2\n",
      "IPython          : 7.16.1\n",
      "pandas_datareader: None\n",
      "bs4              : 4.9.1\n",
      "bottleneck       : None\n",
      "fastparquet      : None\n",
      "gcsfs            : None\n",
      "lxml.etree       : 4.5.1\n",
      "matplotlib       : 3.2.1\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pytables         : None\n",
      "pytest           : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.4.1\n",
      "sqlalchemy       : 1.3.18\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : 1.2.0\n",
      "xlwt             : None\n",
      "xlsxwriter       : None\n",
      "numba            : None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T02:42:48.386927Z",
     "start_time": "2020-08-19T02:42:47.924589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "# Import API key\n",
    "from config import weather_api_key\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T23:36:29.183999Z",
     "start_time": "2020-08-11T23:36:29.180008Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Get Long Lat list of tuples to pass into Weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:57.348708Z",
     "start_time": "2020-08-17T22:02:57.345700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geojson_data = 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:57.698260Z",
     "start_time": "2020-08-17T22:02:57.592543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(geojson_data).json()\n",
    "features = response[\"features\"]\n",
    "test = features[0]['properties']\n",
    "coords_list = []\n",
    "for data in features:\n",
    "    time = data['properties']['time']\n",
    "    magnitude = data['properties']['mag']\n",
    "    place = data['properties']['place']\n",
    "    \n",
    "    long_coords = data[\"geometry\"][\"coordinates\"][0]\n",
    "    lat_coords = data[\"geometry\"][\"coordinates\"][1]\n",
    "    \n",
    "    coords = {\n",
    "            'latlng': f\"{lat_coords}, {long_coords}\",\n",
    "            'lat': lat_coords,\n",
    "            'long': long_coords,\n",
    "            'time': time,\n",
    "            'magnitude': magnitude,\n",
    "            'place': place}\n",
    "    \n",
    "    coords_list.append(coords)\n",
    "# pprint(coords_list)\n",
    "# coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:58.853221Z",
     "start_time": "2020-08-17T22:02:58.849272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(coords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Use Coordinates to get historical weather data.\n",
    "Coordinates represent earthquake lat long location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section creates the table WeatherSeries in the database. WeatherSeries has 4 day weather forecast and matching earthquake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:03:18.860124Z",
     "start_time": "2020-08-17T22:03:18.857132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:11:14.980459Z",
     "start_time": "2020-08-17T22:05:12.104996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(coords_list))\n",
    "\n",
    "tuple_of_data = []\n",
    "add_tuple = {}\n",
    "counter = 0\n",
    "\n",
    "def checkForTwo(number):\n",
    "#     if (int(number)) <= 1:\n",
    "#         number = '1'\n",
    "    if (int(number)) < 10:\n",
    "        number = \"0\" + str(number)\n",
    "    else:\n",
    "#         print(number)\n",
    "        number = str(number)\n",
    "        pass\n",
    "    return number\n",
    "\n",
    "for coordinates in coords_list:\n",
    "    # Lat / long\n",
    "    coords = coordinates['latlng']\n",
    "    \n",
    "    ######################\n",
    "    ## Earthquake time conversion\n",
    "    ######################\n",
    "    earthquake_time = coordinates['time']\n",
    "    dt3 = datetime.fromtimestamp(earthquake_time / 1000)\n",
    "    # Time range end is the day of the earthquake\n",
    "    time_range_end = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(dt3.day)\n",
    "    \n",
    "    # Time range begin is 3 days before the earthquake\n",
    "    four_day_series = dt3 - timedelta(3)\n",
    "    four_day_day = four_day_series\n",
    "    time_range_begin = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(four_day_day.day)\n",
    "    ######################\n",
    "    \n",
    "    base_url = 'http://api.weatherstack.com/historical'\n",
    "    params_weather = {'access_key': weather_api_key, \n",
    "                    'query': coords,\n",
    "                    'historical_date_start': time_range_begin,\n",
    "                    'historical_date_end': time_range_end,\n",
    "                    'units': 'f'\n",
    "                 }\n",
    "    \n",
    "    response = requests.get(base_url, params=params_weather).json()\n",
    "    # url_link = requests.get(base_url, params=params_weather).url\n",
    "    \n",
    "    try: \n",
    "        # extract results\n",
    "        location = response.get('location')\n",
    "        # City, Country, Region\n",
    "        city = location[\"name\"]\n",
    "        country = location[\"country\"]\n",
    "        region = location[\"region\"]\n",
    "\n",
    "        # Historical Only\n",
    "        historical = response['historical']\n",
    "#         print(region)\n",
    "        for hist in historical:\n",
    "            add_tuple = {\n",
    "                'city': city,\n",
    "                'country': country,\n",
    "                'region': region,\n",
    "                'avgtemp': historical[hist]['avgtemp'],\n",
    "                'date': historical[hist]['date'],\n",
    "                'date_epoch': historical[hist]['date_epoch'],\n",
    "                'maxtemp': historical[hist]['maxtemp'],\n",
    "                'mintemp': historical[hist]['mintemp'],\n",
    "                'sunhour': historical[hist]['sunhour'],\n",
    "                'totalsnow': historical[hist]['totalsnow'],\n",
    "                'uv_index': historical[hist]['uv_index'],\n",
    "                'long': coordinates['long'],\n",
    "                'lat': coordinates['lat'],\n",
    "                'time': coordinates['time'],\n",
    "                'magnitude': coordinates['magnitude'],\n",
    "                'place': coordinates['place']\n",
    "            }\n",
    "            tuple_of_data.append(add_tuple)\n",
    "            pbar.update(1)\n",
    "    except TypeError as e:\n",
    "\n",
    "    # print(e)\n",
    "        continue\n",
    "    pbar.update(1)\n",
    "    counter += 1\n",
    "\n",
    "pbar.close() \n",
    "\n",
    "# tuple_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:39.416885Z",
     "start_time": "2020-08-17T22:15:39.411897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tuple_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Saving to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:40.951060Z",
     "start_time": "2020-08-17T22:15:40.948058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:42.460761Z",
     "start_time": "2020-08-17T22:15:42.389833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get time\n",
    "timedate = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "\n",
    "# SAVE: Player_position\n",
    "with open(f'../{timedate}_4_day_weather_for_earthquakes.json', 'w') as fp:\n",
    "    json.dump(tuple_of_data, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T04:30:39.823527Z",
     "start_time": "2020-08-12T04:30:39.820507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del tuple_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Opening JSON .. Do not have to run the api again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:07.166731Z",
     "start_time": "2020-08-17T22:16:07.153731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open raw json to parse\n",
    "with open('../2020-08-17_15_15_40_4_day_weather_for_earthquakes.json', 'r') as f:\n",
    "    weather_earthquake_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:10.456725Z",
     "start_time": "2020-08-17T22:16:10.448778Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataframe to see raw(cleaned) data\n",
    "all_logs = pd.DataFrame(weather_earthquake_data)\n",
    "# all_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T17:05:49.615599Z",
     "start_time": "2020-08-13T17:05:49.595652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:31.551675Z",
     "start_time": "2020-08-17T22:16:31.547662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to clear out the db\n",
    "# ----------------------------------\n",
    "# # Session.rollback(self)\n",
    "# Base.metadata.drop_all(engine)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:32.372963Z",
     "start_time": "2020-08-17T22:16:32.369969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete previous entries\n",
    "# del WeatherSeries\n",
    "# del LatLong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:04.975795Z",
     "start_time": "2020-08-19T00:50:04.972684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# import requests\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "# Import API key\n",
    "# from config import weather_api_key\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:05.316875Z",
     "start_time": "2020-08-19T00:50:05.196594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# ----------------------------------\n",
    "# Imports the method used for connecting to DBs\n",
    "from sqlalchemy import create_engine\n",
    "# Allow us to declare column types\n",
    "from sqlalchemy import Column, Integer, String, Text, DateTime, Float, Boolean, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:05.383743Z",
     "start_time": "2020-08-19T00:50:05.380751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Weather and Earthquake Classes\n",
    "# ----------------------------------\n",
    "# Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:05.730924Z",
     "start_time": "2020-08-19T00:50:05.720950Z"
    }
   },
   "outputs": [],
   "source": [
    "## Class base template to upload to sqlite\n",
    "class WeatherSeries(Base):\n",
    "    __tablename__ = 'weatherSeries'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    city = Column(String(50))\n",
    "    country = Column(String(200))\n",
    "    region = Column(String(80))\n",
    "    avgtemp = Column(Float)\n",
    "    date = Column(String(12))\n",
    "    date_epoch = Column(Float)\n",
    "    maxtemp = Column(Float)\n",
    "    mintemp = Column(Float)\n",
    "    sunhour = Column(Float)\n",
    "    totalsnow = Column(Float)\n",
    "    uv_index = Column(Float)\n",
    "    magnitude = Column(Float)\n",
    "    place = Column(String(80))\n",
    "    lat = Column(String(12))\n",
    "    long = Column(String(12))\n",
    "    \n",
    "# class LatLong(Base):\n",
    "#     __tablename__ = 'latlong'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     lat = Column(String(12))\n",
    "#     long = Column(String(12))\n",
    "#     lat_rel = Column(Integer, ForeignKey('weatherSeries.id'))\n",
    "#     weatherSer = relationship(WeatherSeries, primaryjoin=lat_rel == WeatherSeries.id)\n",
    "#     latlong_id = Column(String,ForeignKey('latlong.id'))\n",
    "#     latlong_rel = relationship(LatLong)\n",
    "#     lat = Column(String(12))\n",
    "#     long = Column(String(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:06.227431Z",
     "start_time": "2020-08-19T00:50:06.215110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Database Connection\n",
    "# ----------------------------------\n",
    "# Creates a connection to our DB\n",
    "# Engine opens the door. Conn is the walk through sign\n",
    "engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "conn = engine.connect()\n",
    "# Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "# ----------------------------------\n",
    "# Create (if not already in existence) the tables associated with our classes.\n",
    "Base.metadata.create_all(engine)\n",
    "# Create a Session Object to Connect to DB\n",
    "# ----------------------------------\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:36.164459Z",
     "start_time": "2020-08-17T22:16:36.161467Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Add weather series to sql\n",
    "# x=0\n",
    "# while x <= (len(all_logs) - 1):    \n",
    "#     lat_long_data = LatLong(\n",
    "#         lat = all_logs[\"lat\"][x],\n",
    "#         long = all_logs[\"long\"][x]\n",
    "#         )\n",
    "#     x+=1\n",
    "#     # Add Records to the Appropriate DB\n",
    "#     # ----------------------------------\n",
    "#     # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "#     session.add(lat_long_data)\n",
    "#     # session.add(earthquake_data)\n",
    "#     session.commit()\n",
    "# print('Complete: Uploaded to SQLite DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:37.204498Z",
     "start_time": "2020-08-17T22:16:37.198482Z"
    }
   },
   "outputs": [],
   "source": [
    "## Function: Add Weather Series to sql\n",
    "def addToSQL(all_logs):\n",
    "    x=0\n",
    "    while x <= (len(all_logs) - 1):\n",
    "        try: \n",
    "            weather_data = WeatherSeries(\n",
    "                city = all_logs[\"city\"][x],\n",
    "                country = all_logs[\"country\"][x],\n",
    "                region = all_logs[\"region\"][x],\n",
    "                avgtemp = all_logs[\"avgtemp\"][x],\n",
    "                date = all_logs[\"date\"][x],\n",
    "                date_epoch = all_logs[\"date_epoch\"][x],\n",
    "                maxtemp = all_logs[\"maxtemp\"][x],\n",
    "                mintemp = all_logs[\"mintemp\"][x],\n",
    "                sunhour = all_logs[\"sunhour\"][x],\n",
    "                totalsnow = all_logs[\"totalsnow\"][x],\n",
    "                uv_index = all_logs[\"uv_index\"][x],\n",
    "                magnitude = all_logs[\"magnitude\"][x],\n",
    "                place = all_logs[\"place\"][x],\n",
    "                lat = all_logs[\"lat\"][x],\n",
    "                long = all_logs[\"long\"][x],\n",
    "                )\n",
    "            x+=1\n",
    "        except OperationalError:\n",
    "            pass\n",
    "            \n",
    "        # Add Records to the Appropriate DB\n",
    "        # ----------------------------------\n",
    "        # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "        session.add(weather_data)\n",
    "        # session.add(earthquake_data)\n",
    "        session.commit()\n",
    "    return 'Complete: Uploaded to SQLite DB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:51.105872Z",
     "start_time": "2020-08-17T22:16:38.406908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addToSQL(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:08:09.623567Z",
     "start_time": "2020-08-18T07:08:09.594643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify Data \n",
    "# Create DataFrame from sql table Weather\n",
    "weather_data_df = pd.read_sql(\"SELECT * FROM WeatherSeries\", conn)\n",
    "weather_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:30.857201Z",
     "start_time": "2020-08-18T03:24:30.854208Z"
    }
   },
   "outputs": [],
   "source": [
    "# avg = weather_data_df[weather_data_df['magnitude'] > 6.0]\n",
    "# avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python call from db. For flask to web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:11.279195Z",
     "start_time": "2020-08-19T00:50:11.275205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "# Go to existing database with automap_base\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "# Work through mapper to use python code\n",
    "from sqlalchemy.orm import Session\n",
    "# Inspect with python\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy import desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:50:11.718716Z",
     "start_time": "2020-08-19T00:50:11.708562Z"
    }
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "# Check db table names\n",
    "# Base.classes.keys()\n",
    "weather_table = Base.classes.weatherSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysisChartCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:58:31.596729Z",
     "start_time": "2020-08-19T00:58:31.142660Z"
    }
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "weather_table = Base.classes.weatherSeries\n",
    "analysis_container = session.query(weather_table).order_by(desc(weather_table.date)).all()        \n",
    "analysis_list_temp = []\n",
    "x=1\n",
    "\n",
    "for data in analysis_container:\n",
    "    # get specific data from db\n",
    "    container = {\n",
    "        \"date\": data.date,\n",
    "        \"magnitude\": data.magnitude,\n",
    "        \"maxtemp\": data.maxtemp,\n",
    "        \"mintemp\": data.mintemp,\n",
    "#         \"avgtemp\": data.avgtemp,\n",
    "        \"lat\": data.lat,\n",
    "        }\n",
    "    analysis_list_temp.append(container)\n",
    "\n",
    "# Create df for parsing    \n",
    "temp_df = pd.DataFrame(analysis_list_temp)\n",
    "# Sort by lat and date, reset index\n",
    "temp_df = temp_df.sort_values(by=['lat', 'date'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Make copy of df, remove 2nd and 3rd log keeping 1st and 4th log of one eq entry.\n",
    "run_df = temp_df.copy()\n",
    "while x < len(temp_df.index):\n",
    "    run_df=run_df.drop(x)\n",
    "    x+=1\n",
    "    run_df=run_df.drop(x)\n",
    "    x+=3\n",
    "\n",
    "# Reset index \n",
    "run_df = run_df.reset_index(drop=True) \n",
    "\n",
    "# get difference of weather change from day of eq and few days before\n",
    "i = 0\n",
    "new_col = []\n",
    "# Icon list will tell style which icon to display\n",
    "icon_list = []\n",
    "while i < len(run_df.index):\n",
    "#     for data in run_df.index:\n",
    "    first = run_df.iloc[i,2]\n",
    "    second = run_df.iloc[i+1, 2]\n",
    "    difference = first - second\n",
    "    new_col.append(difference)\n",
    "    new_col.append(difference)\n",
    "    i+=2    \n",
    "# Add new list to df as a new column  \n",
    "run_df['difference'] = new_col     \n",
    "# Count up, nochange, down\n",
    "up_count = 0\n",
    "nochange_count = 0\n",
    "down_count = 0\n",
    "for x in run_df['difference']:\n",
    "    if x > 0:\n",
    "        icon = \"up\"\n",
    "        up_count+=1\n",
    "        icon_list.append(icon)\n",
    "    elif x == 0:\n",
    "        icon = \"nochange\"\n",
    "        nochange_count+=1\n",
    "        icon_list.append(icon)\n",
    "    else:\n",
    "        icon = \"down\"\n",
    "        down_count+=1\n",
    "        icon_list.append(icon)\n",
    "\n",
    "# Add new list to df as a new column\n",
    "run_df['icon'] = icon_list    \n",
    "# select only the columns we need\n",
    "run_df = run_df[['date','magnitude','lat','difference','icon']]\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "run_df2 = run_df.copy()\n",
    "v = 1\n",
    "while v < len(run_df.index):\n",
    "    run_df2=run_df2.drop(v)\n",
    "    v+=2\n",
    "run_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T01:19:04.647645Z",
     "start_time": "2020-08-19T01:19:04.131864Z"
    }
   },
   "outputs": [],
   "source": [
    "def analysisChart():    \n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    analysis_container = session.query(weather_table).order_by(desc(weather_table.date)).all()        \n",
    "    analysis_list_temp = []\n",
    "    x=1\n",
    "\n",
    "    for data in analysis_container:\n",
    "        # get specific data from db\n",
    "        container = {\n",
    "            \"date\": data.date,\n",
    "            \"magnitude\": data.magnitude,\n",
    "            \"maxtemp\": data.maxtemp,\n",
    "            \"mintemp\": data.mintemp,\n",
    "    #         \"avgtemp\": data.avgtemp,\n",
    "            \"lat\": data.lat,\n",
    "            }\n",
    "        analysis_list_temp.append(container)\n",
    "\n",
    "    # Create df for parsing    \n",
    "    temp_df = pd.DataFrame(analysis_list_temp)\n",
    "    # Sort by lat and date, reset index\n",
    "    temp_df = temp_df.sort_values(by=['lat', 'date'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Make copy of df, remove 2nd and 3rd log keeping 1st and 4th log of one eq entry.\n",
    "    run_df = temp_df.copy()\n",
    "    while x < len(temp_df.index):\n",
    "        run_df=run_df.drop(x)\n",
    "        x+=1\n",
    "        run_df=run_df.drop(x)\n",
    "        x+=3\n",
    "\n",
    "    # Reset index \n",
    "    run_df = run_df.reset_index(drop=True) \n",
    "\n",
    "    # get difference of weather change from day of eq and few days before\n",
    "    i = 0\n",
    "    new_col = []\n",
    "    # Icon list will tell style which icon to display\n",
    "    icon_list = []\n",
    "    while i < len(run_df.index):\n",
    "    #     for data in run_df.index:\n",
    "        first = run_df.iloc[i,2]\n",
    "        second = run_df.iloc[i+1, 2]\n",
    "        difference = first - second\n",
    "        new_col.append(difference)\n",
    "        new_col.append(difference)\n",
    "        i+=2\n",
    "\n",
    "    # Add new list to df as a new column  \n",
    "    run_df['difference'] = new_col  \n",
    "    \n",
    "\n",
    "    # Remove duplicates\n",
    "    run_df2 = run_df.copy()\n",
    "    v = 1\n",
    "    while v < len(run_df.index):\n",
    "        run_df2=run_df2.drop(v)\n",
    "        v+=2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Count up, nochange, down\n",
    "    up_count = 0\n",
    "    nochange_count = 0\n",
    "    down_count = 0\n",
    "    for x in run_df2['difference']:\n",
    "        if x > 0:\n",
    "            icon = \"up\"\n",
    "            up_count+=1\n",
    "            icon_list.append(icon)\n",
    "        elif x == 0:\n",
    "            icon = \"nochange\"\n",
    "            nochange_count+=1\n",
    "            icon_list.append(icon)\n",
    "        else:\n",
    "            icon = \"down\"\n",
    "            down_count+=1\n",
    "            icon_list.append(icon)\n",
    "\n",
    "    # Add new list to df as a new column\n",
    "    run_df2['icon'] = icon_list    \n",
    "    # select only the columns we need\n",
    "    run_df2 = run_df2[['date','magnitude','lat','difference','icon']]\n",
    "\n",
    "    # # Turn df into list of tuples\n",
    "    records = run_df2.to_records(index=False)\n",
    "    analysis_chart = list(records)\n",
    "\n",
    "    # Create list of tuple\n",
    "    analysis_list = []\n",
    "    for data in analysis_chart:\n",
    "        container2 = {\n",
    "            \"date\": data.date, \n",
    "            \"magnitude\": data.magnitude, \n",
    "            \"lat\": data.lat, \n",
    "            \"difference\": data.difference, \n",
    "            \"icon\": data.icon,\n",
    "            }\n",
    "        analysis_list.append(container2)\n",
    "\n",
    "    diff_count = len(run_df2['difference'])\n",
    "    above_percentage = \"{:.0%}\".format(up_count / diff_count)\n",
    "    atzero_percentage = \"{:.0%}\".format(nochange_count / diff_count)\n",
    "    belowzero_percentage = \"{:.0%}\".format(down_count / diff_count)\n",
    "    container3 = {\n",
    "                \"abovezero\": up_count,\n",
    "                \"abovezeropercent\": above_percentage,\n",
    "                \"atzero\": nochange_count, \n",
    "                \"atzeropercent\": atzero_percentage, \n",
    "                \"belowzero\": down_count, \n",
    "                \"belowzeropercent\": belowzero_percentage,\n",
    "                }\n",
    "\n",
    "    analysis_list.append(container3)     \n",
    "    return analysis_list\n",
    "\n",
    "analysis_list = analysisChart()\n",
    "analysis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:55:45.941241Z",
     "start_time": "2020-08-18T07:55:45.934263Z"
    }
   },
   "outputs": [],
   "source": [
    "analysisChart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:54:29.257559Z",
     "start_time": "2020-08-18T07:54:29.254534Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_count = len(run_df['difference'])/2\n",
    "diff_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:47:53.805337Z",
     "start_time": "2020-08-18T07:47:53.796360Z"
    }
   },
   "outputs": [],
   "source": [
    "run_df['icon'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T00:13:00.912268Z",
     "start_time": "2020-08-18T00:13:00.898282Z"
    }
   },
   "outputs": [],
   "source": [
    "run_df.sort_values(by='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T01:19:35.744951Z",
     "start_time": "2020-08-19T01:19:35.727401Z"
    }
   },
   "outputs": [],
   "source": [
    "def analysisChartCall():\n",
    "    # Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "    Base = declarative_base()\n",
    "    ## Class base template to upload to sqlite\n",
    "    class WeatherSeries(Base):\n",
    "        __tablename__ = 'weatherSeries'\n",
    "\n",
    "        id = Column(Integer, primary_key=True)\n",
    "        city = Column(String(50))\n",
    "        country = Column(String(200))\n",
    "        region = Column(String(80))\n",
    "        avgtemp = Column(Float)\n",
    "        date = Column(String(12))\n",
    "        date_epoch = Column(Float)\n",
    "        maxtemp = Column(Float)\n",
    "        mintemp = Column(Float)\n",
    "        sunhour = Column(Float)\n",
    "        totalsnow = Column(Float)\n",
    "        uv_index = Column(Float)\n",
    "        magnitude = Column(Float)\n",
    "        place = Column(String(80))\n",
    "        lat = Column(String(12))\n",
    "        long = Column(String(12))\n",
    "\n",
    "    # Create Database Connection\n",
    "    # ----------------------------------\n",
    "    # Creates a connection to our DB\n",
    "    # Engine opens the door. Conn is the walk through sign\n",
    "    engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "    conn = engine.connect()\n",
    "    # Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "    # ----------------------------------\n",
    "    # Create (if not already in existence) the tables associated with our classes.\n",
    "    Base.metadata.create_all(engine)\n",
    "    # Create a Session Object to Connect to DB\n",
    "    # ----------------------------------\n",
    "    session = Session(bind=engine)\n",
    "\n",
    "    def analysisChart():    \n",
    "        Base = automap_base()\n",
    "        Base.prepare(engine, reflect=True)\n",
    "        weather_table = Base.classes.weatherSeries\n",
    "        analysis_container = session.query(weather_table).order_by(desc(weather_table.date)).all()        \n",
    "        analysis_list_temp = []\n",
    "        x=1\n",
    "\n",
    "        for data in analysis_container:\n",
    "            # get specific data from db\n",
    "            container = {\n",
    "                \"date\": data.date,\n",
    "                \"magnitude\": data.magnitude,\n",
    "                \"maxtemp\": data.maxtemp,\n",
    "                \"mintemp\": data.mintemp,\n",
    "        #         \"avgtemp\": data.avgtemp,\n",
    "                \"lat\": data.lat,\n",
    "                }\n",
    "            analysis_list_temp.append(container)\n",
    "\n",
    "        # Create df for parsing    \n",
    "        temp_df = pd.DataFrame(analysis_list_temp)\n",
    "        # Sort by lat and date, reset index\n",
    "        temp_df = temp_df.sort_values(by=['lat', 'date'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # Make copy of df, remove 2nd and 3rd log keeping 1st and 4th log of one eq entry.\n",
    "        run_df = temp_df.copy()\n",
    "        while x < len(temp_df.index):\n",
    "            run_df=run_df.drop(x)\n",
    "            x+=1\n",
    "            run_df=run_df.drop(x)\n",
    "            x+=3\n",
    "\n",
    "        # Reset index \n",
    "        run_df = run_df.reset_index(drop=True) \n",
    "\n",
    "        # get difference of weather change from day of eq and few days before\n",
    "        i = 0\n",
    "        new_col = []\n",
    "        # Icon list will tell style which icon to display\n",
    "        icon_list = []\n",
    "        while i < len(run_df.index):\n",
    "        #     for data in run_df.index:\n",
    "            first = run_df.iloc[i,2]\n",
    "            second = run_df.iloc[i+1, 2]\n",
    "            difference = first - second\n",
    "            new_col.append(difference)\n",
    "            new_col.append(difference)\n",
    "            i+=2\n",
    "\n",
    "        # Add new list to df as a new column  \n",
    "        run_df['difference'] = new_col  \n",
    "\n",
    "\n",
    "        # Remove duplicates\n",
    "        run_df2 = run_df.copy()\n",
    "        v = 1\n",
    "        while v < len(run_df.index):\n",
    "            run_df2=run_df2.drop(v)\n",
    "            v+=2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Count up, nochange, down\n",
    "        up_count = 0\n",
    "        nochange_count = 0\n",
    "        down_count = 0\n",
    "        for x in run_df2['difference']:\n",
    "            if x > 0:\n",
    "                icon = \"up\"\n",
    "                up_count+=1\n",
    "                icon_list.append(icon)\n",
    "            elif x == 0:\n",
    "                icon = \"nochange\"\n",
    "                nochange_count+=1\n",
    "                icon_list.append(icon)\n",
    "            else:\n",
    "                icon = \"down\"\n",
    "                down_count+=1\n",
    "                icon_list.append(icon)\n",
    "\n",
    "        # Add new list to df as a new column\n",
    "        run_df2['icon'] = icon_list    \n",
    "        # select only the columns we need\n",
    "        run_df2 = run_df2[['date','magnitude','lat','difference','icon']]\n",
    "\n",
    "        # # Turn df into list of tuples\n",
    "        records = run_df2.to_records(index=False)\n",
    "        analysis_chart = list(records)\n",
    "\n",
    "        # Create list of tuple\n",
    "        analysis_list = []\n",
    "        for data in analysis_chart:\n",
    "            container2 = {\n",
    "                \"date\": data.date, \n",
    "                \"magnitude\": data.magnitude, \n",
    "                \"lat\": data.lat, \n",
    "                \"difference\": data.difference, \n",
    "                \"icon\": data.icon,\n",
    "                }\n",
    "            analysis_list.append(container2)\n",
    "\n",
    "        diff_count = len(run_df2['difference'])\n",
    "        above_percentage = \"{:.0%}\".format(up_count / diff_count)\n",
    "        atzero_percentage = \"{:.0%}\".format(nochange_count / diff_count)\n",
    "        belowzero_percentage = \"{:.0%}\".format(down_count / diff_count)\n",
    "        container3 = {\n",
    "                    \"abovezero\": up_count,\n",
    "                    \"abovezeropercent\": above_percentage,\n",
    "                    \"atzero\": nochange_count, \n",
    "                    \"atzeropercent\": atzero_percentage, \n",
    "                    \"belowzero\": down_count, \n",
    "                    \"belowzeropercent\": belowzero_percentage,\n",
    "                    }\n",
    "\n",
    "        analysis_list.append(container3)     \n",
    "        return analysis_list\n",
    "\n",
    "    analysis_list = analysisChart()\n",
    "    return analysis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T01:19:36.433063Z",
     "start_time": "2020-08-19T01:19:35.964753Z"
    }
   },
   "outputs": [],
   "source": [
    "test = analysisChartCall()[-1]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:33.512474Z",
     "start_time": "2020-08-17T22:02:33.500521Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "## Facts \n",
    "##################################################################\n",
    "\n",
    "def aboveSixQuakeCall():\n",
    "    # Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "    Base = declarative_base()\n",
    "    ## Class base template to upload to sqlite\n",
    "    class WeatherSeries(Base):\n",
    "        __tablename__ = 'weatherSeries'\n",
    "\n",
    "        id = Column(Integer, primary_key=True)\n",
    "        city = Column(String(50))\n",
    "        country = Column(String(200))\n",
    "        region = Column(String(80))\n",
    "        avgtemp = Column(Float)\n",
    "        date = Column(String(12))\n",
    "        date_epoch = Column(Float)\n",
    "        maxtemp = Column(Float)\n",
    "        mintemp = Column(Float)\n",
    "        sunhour = Column(Float)\n",
    "        totalsnow = Column(Float)\n",
    "        uv_index = Column(Float)\n",
    "        magnitude = Column(Float)\n",
    "        place = Column(String(80))\n",
    "        lat = Column(String(12))\n",
    "        long = Column(String(12))\n",
    "\n",
    "    # Create Database Connection\n",
    "    # ----------------------------------\n",
    "    # Creates a connection to our DB\n",
    "    # Engine opens the door. Conn is the walk through sign\n",
    "    engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "    conn = engine.connect()\n",
    "    # Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "    # ----------------------------------\n",
    "    # Create (if not already in existence) the tables associated with our classes.\n",
    "    Base.metadata.create_all(engine)\n",
    "    # Create a Session Object to Connect to DB\n",
    "    # ----------------------------------\n",
    "    session = Session(bind=engine)\n",
    "\n",
    "    def aboveSixQuake():\n",
    "        Base = automap_base()\n",
    "        Base.prepare(engine, reflect=True)\n",
    "        # Check db table names\n",
    "        # Base.classes.keys()\n",
    "        weather_table = Base.classes.weatherSeries\n",
    "        \n",
    "#         weather_container = session.query(weather_table).order_by(desc(weather_table.magnitude)).limit(1).all()\n",
    "        \n",
    "        weather_container = session.query(weather_table).filter(weather_table.magnitude > 6).all()\n",
    "        weather_facts = []\n",
    "        magnitude_list = []\n",
    "        count = 0\n",
    "        for data in weather_container:\n",
    "            count += 1\n",
    "            \n",
    "            # make a list of magnitudes recorded greater than 6 and get avg temp\n",
    "            magnitude_list.append(data.avgtemp)\n",
    "            magnitude = data.magnitude\n",
    "            magnitude_keep = 6\n",
    "            # Get highest recorded earthquake\n",
    "            if data.magnitude > magnitude_keep:\n",
    "                magnitude_keep = data.magnitude\n",
    "                location = data.country\n",
    "                city = data.city\n",
    "                temp_low = data.mintemp\n",
    "                temp_high = data.maxtemp\n",
    "                avg_temp_at_time = data.avgtemp\n",
    "                date = data.date\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        def spellDate(datestring):\n",
    "            date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "            month_name = date_time_obj.strftime(\"%B\")\n",
    "            day = date_time_obj.strftime(\"%d\")\n",
    "            year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "            month_day = month_name + \" \" + day\n",
    "            month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "            date = {\n",
    "                \"month_day\": month_day,\n",
    "                \"month_day_year\": month_day_year,\n",
    "            }\n",
    "            return date  \n",
    "\n",
    "  \n",
    "        # Get avgtemp from list        \n",
    "        def Average(lst): \n",
    "            return sum(lst) / len(lst) \n",
    "        quake_avg = Average(magnitude_list)\n",
    "\n",
    "\n",
    "        spell_dates = spellDate(date)\n",
    "        \n",
    "        container = {\n",
    "            \"count\": count, \n",
    "            \"avgtemp\": quake_avg,\n",
    "            \"highest_magnitude\": magnitude_keep, \n",
    "            \"highest_city\": city,\n",
    "            \"highest_location\": location,\n",
    "            \"temp_low\": temp_low,\n",
    "            \"temp_high\": temp_high,\n",
    "            \"avg_temp_at_time\": avg_temp_at_time,\n",
    "            \"date\": spell_dates,\n",
    "            \n",
    "        }\n",
    "        weather_facts.append(container)\n",
    "        return weather_facts\n",
    "\n",
    "    weather_facts = aboveSixQuake()\n",
    "\n",
    "    # Return results\n",
    "    return weather_facts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:03:27.310439Z",
     "start_time": "2020-08-16T10:03:27.304455Z"
    }
   },
   "outputs": [],
   "source": [
    "def latestQuakes():\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    weather_container = session.query(weather_table).order_by(desc(weather_table.date)).limit(5).all()\n",
    "\n",
    "    weather_latest5 = []\n",
    "    for data in weather_container:\n",
    "        container = {\n",
    "            \"date\": data.date, \n",
    "            \"city\": data.city, \n",
    "            \"country\": data.country, \n",
    "            \"region\": data.region, \n",
    "            \"place\": data.place,\n",
    "            \"mintemp\": data.mintemp, \n",
    "            \"maxtemp\": data.maxtemp, \n",
    "            \"avgtemp\": data.avgtemp,\n",
    "            \"magnitude\": data.magnitude, \n",
    "            }\n",
    "        weather_latest5.append(container)\n",
    "    return weather_latest5\n",
    "    #     print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T09:59:03.333466Z",
     "start_time": "2020-08-16T09:59:03.322493Z"
    }
   },
   "outputs": [],
   "source": [
    "last_five_quakes_df = pd.DataFrame(last_five_quakes)\n",
    "last_five_quakes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:06:40.407559Z",
     "start_time": "2020-08-15T03:06:40.402537Z"
    }
   },
   "outputs": [],
   "source": [
    "# def weatherTimeSeries(query_call):\n",
    "#     Base = automap_base()\n",
    "#     Base.prepare(engine, reflect=True)\n",
    "#     # Check db table names\n",
    "#     # Base.classes.keys()\n",
    "#     weather_table = Base.classes.weatherSeries\n",
    "#     weather_container = session.query(weather_table).filter(weather_table.lat == query_call).all()\n",
    "#     weather_data = []\n",
    "#     for data in weather_container:\n",
    "#         container = {\n",
    "#             \"city\": data.city, \n",
    "#             \"country\": data.country, \n",
    "#             \"region\": data.region, \n",
    "#             \"avgtemp\": data.avgtemp, \n",
    "#             \"date\": data.date, \n",
    "#             \"date_epoch\": data.date_epoch, \n",
    "#             \"maxtemp\": data.maxtemp, \n",
    "#             \"mintemp\": data.mintemp, \n",
    "#             \"sunhour\": data.sunhour, \n",
    "#             \"totalsnow\": data.totalsnow, \n",
    "#             \"uv_index\": data.uv_index, \n",
    "#             \"magnitude\": data.magnitude, \n",
    "#             \"place\": data.place, \n",
    "#             \"lat\": data.lat, \n",
    "#             \"long\": data.long\n",
    "#         }\n",
    "#         weather_data.append(container)\n",
    "#     return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude = '53.42'\n",
    "# query_from_db_to_web = weatherTimeSeries(latitude)\n",
    "# query_from_db_to_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:37:15.256021Z",
     "start_time": "2020-08-16T21:37:15.251005Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dt3 = datetime.fromtimestamp(1597074974330 / 1000)\n",
    "dt3.strftime(\"%B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:38:42.330991Z",
     "start_time": "2020-08-16T21:38:42.324983Z"
    }
   },
   "outputs": [],
   "source": [
    "dt3 = datetime.fromtimestamp(1597074974330 / 1000)\n",
    "month_name = dt3.strftime(\"%B\")\n",
    "day = dt3.strftime(\"%d\")\n",
    "year = dt3.strftime(\"%Y\")\n",
    "\n",
    "month_day = month_name + \" \" + day\n",
    "month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "date = {\n",
    "    \"month_day\": month_day,\n",
    "    \"month_day_year\": month_day_year,\n",
    "}\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:39:45.230496Z",
     "start_time": "2020-08-16T21:39:45.224511Z"
    }
   },
   "outputs": [],
   "source": [
    "def spellDateUnix(datestring):\n",
    "    dt3 = datetime.fromtimestamp(datestring / 1000)\n",
    "    month_name = dt3.strftime(\"%B\")\n",
    "    day = dt3.strftime(\"%d\")\n",
    "    year = dt3.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "\n",
    "    return date\n",
    "spellDateUnix(1597074974330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:25.068042Z",
     "start_time": "2020-08-16T03:18:25.059038Z"
    }
   },
   "outputs": [],
   "source": [
    "def spellDate(datestring):\n",
    "    date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "    month_name = date_time_obj.strftime(\"%B\")\n",
    "    day = date_time_obj.strftime(\"%d\")\n",
    "    year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "    return date\n",
    "\n",
    "\n",
    "def aboveSixQuake():\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    # Check db table names\n",
    "    # Base.classes.keys()\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    weather_container = session.query(weather_table).filter(weather_table.magnitude > 6).all()\n",
    "    weather_facts = []\n",
    "    magnitude_list = []\n",
    "    count = 0\n",
    "    for data in weather_container:\n",
    "        count += 1\n",
    "        \n",
    "        # make a list of magnitudes recorded greater than 6 and get avg temp\n",
    "        magnitude_list.append(data.avgtemp)\n",
    "        magnitude = data.magnitude\n",
    "        magnitude_keep = 6\n",
    "        # Get highest recorded earthquake\n",
    "        if data.magnitude > magnitude_keep:\n",
    "            magnitude_keep = data.magnitude\n",
    "            location = data.country\n",
    "            city = data.city\n",
    "            temp_low = data.mintemp\n",
    "            temp_high = data.maxtemp\n",
    "            avg_temp_at_time = data.avgtemp\n",
    "            date = data.date\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Get avgtemp from list        \n",
    "    def Average(lst): \n",
    "        return sum(lst) / len(lst) \n",
    "    quake_avg = Average(magnitude_list)\n",
    "\n",
    "\n",
    "    spell_dates = spellDate(date)\n",
    "    \n",
    "    container = {\n",
    "        \"count\": count, \n",
    "        \"avgtemp\": quake_avg,\n",
    "        \"highest_magnitude\": magnitude_keep, \n",
    "        \"highest_city\": city,\n",
    "        \"highest_location\": location,\n",
    "        \"temp_low\": temp_low,\n",
    "        \"temp_high\": temp_high,\n",
    "        \"avg_temp_at_time\": avg_temp_at_time,\n",
    "        \"date\": spell_dates,\n",
    "         \n",
    "    }\n",
    "    weather_facts.append(container)\n",
    "    return weather_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:25.305858Z",
     "start_time": "2020-08-16T03:18:25.282918Z"
    }
   },
   "outputs": [],
   "source": [
    "query_from_db_to_web = aboveSixQuake()\n",
    "query_from_db_to_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Date to \"August 10, 2020\" and \"August 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T01:14:15.836525Z",
     "start_time": "2020-08-16T01:14:15.832508Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:31.806564Z",
     "start_time": "2020-08-16T03:18:31.803571Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T01:27:05.971764Z",
     "start_time": "2020-08-16T01:27:05.967774Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "def spellDate(datestring):\n",
    "    \n",
    "    date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "    month_name = date_time_obj.strftime(\"%B\")\n",
    "    day = date_time_obj.strftime(\"%d\")\n",
    "    year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "    \n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlong_container = session.query(latlong_table).filter(latlong_table.lat == '').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:18:50.959907Z",
     "start_time": "2020-08-13T03:18:50.956886Z"
    }
   },
   "outputs": [],
   "source": [
    "# for data in latlong_table:\n",
    "#     print(f\"Date: {data.lat}, Temp: {data.long}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:17:44.639252Z",
     "start_time": "2020-08-13T03:17:44.635284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join two tables in the db\n",
    "# def join_example():\n",
    "#     records = session.query(WeatherSeries).\\\n",
    "#         join(LatLong, LatLong.id == WeatherSeries.id).all()\n",
    "# #     print(records)\n",
    "#     for record in records:\n",
    "#         recordObject = {\n",
    "#             'city': record.city,\n",
    "#             'country': record.country,\n",
    "#             'date': record.date,\n",
    "#             'maxtemp': record.maxtemp,\n",
    "#             'latlong_rel': record.latlong_rel\n",
    "#         }\n",
    "#         print(recordObject)\n",
    "# join_example()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:10:23.766957Z",
     "start_time": "2020-08-13T03:10:23.751969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from sql table Weather\n",
    "# weather_data_df = pd.read_sql(\"SELECT * FROM LatLong\", conn)\n",
    "# weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "## KEEP !!\n",
    "## DO NOT DELETE ALL THIS\n",
    "###\n",
    "\n",
    "# Create a Specific Instance of the \"weather_data\" and \"earthquake_data\" classes\n",
    "# ----------------------------------\n",
    "# Data needs to pass through this. A for loop while need to be created to consistantly send multiple files\n",
    "# weather_data = WeatherSeries(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     city = '',\n",
    "#     country = '',\n",
    "#     region = '',\n",
    "#     avgtemp = '',\n",
    "#     date_epoch = '',\n",
    "#     maxtemp = '',\n",
    "#     mintemp = '',\n",
    "#     sunhour = '',\n",
    "#     totalsnow = '',\n",
    "#     uv_index = '',\n",
    "#     )\n",
    "\n",
    "# earthquake_data = Earthquake(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     mag = '',\n",
    "#     location = ''\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:56.043030Z",
     "start_time": "2020-08-12T10:27:56.040038Z"
    }
   },
   "outputs": [],
   "source": [
    "# def checkEqual3(lst):\n",
    "#     return lst[1:] == lst[:-1]\n",
    "\n",
    "# def checkRowValueDups(data):\n",
    "#     dictOfKeys = data.keys()\n",
    "#     for column in data:\n",
    "#         column_values = data[column].to_list()\n",
    "#         result = checkEqual3(column_values)\n",
    "# #         print('passed.')\n",
    "#     if result == True:\n",
    "#         all_logs_df = all_logs.iloc[0:1, 0:]\n",
    "#     else:\n",
    "#         print(\"Couldnt complete cleaning. Different value found in column where only duplicates live. Check function checkRowValueDups() for information\")\n",
    "#     return all_logs_df\n",
    "\n",
    "# all_logs_df = checkRowValueDups(all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:58.503194Z",
     "start_time": "2020-08-12T10:27:58.500244Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_logs_df['2020-08-03'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff = (list(all_logs.itertuples(index=False, name=None)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
